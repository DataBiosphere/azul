workflow:
  name: $azul_gitlab_pipeline_name
  rules:
    - if: $CI_PIPELINE_SOURCE == 'push' && $CI_COMMIT_BRANCH
      variables:
        azul_gitlab_pipeline_name: $CI_COMMIT_TITLE
    - if: $CI_PIPELINE_SOURCE == 'schedule'
      variables:
        azul_gitlab_pipeline_name: Scheduled $azul_gitlab_schedule

variables:
  azul_docker_image: $CI_REGISTRY_IMAGE
  azul_docker_image_tag: $CI_PIPELINE_ID

stages:
  - build_image
  - setup
  - test
  - deploy
  - early_reindex
  - integration_test
  - teardown
  - reindex
  - schedule

.on_push:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'push' && $CI_COMMIT_BRANCH

build_image:
  # Build an image containing the build prerequisites (python, terraform, etc).
  # This lets us exploit Docker's layer caching to speed up the build. The
  # image will only be rebuilt after changes to the Dockerfile, 
  # requirements*.txt, common.mk and the Makefile.
  extends: .on_push
  stage: build_image
  rules:
    - if: $CI_COMMIT_BRANCH
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY_IMAGE
    - make docker_dev_push .gitlab.env
  artifacts:
    reports:
      dotenv: .gitlab.env

.base:
  dependencies:
    - build_image
  image: $BUILD_IMAGE
  before_script:
    - cp -vR /etc/gitlab/azul/* . # Copy files like environment.local into the build directory.
    - source /build/.venv/bin/activate
    - pip list
    - source environment  # load global defaults
    - deployment=$(PYTHONPATH=src python scripts/check_branch.py --print)
    - _link $deployment
    - _refresh
    - status_context="gitlab/${azul_gitlab_instance_name}/${AZUL_DEPLOYMENT_STAGE}"
    - make clean

.base_on_push:
  extends:
    - .on_push
    - .base

setup:
  extends: .base_on_push
  stage: setup
  script:
    - python scripts/github_status_check.py "${status_context}" pending

test:
  extends: .base_on_push
  stage: test
  script:
    - make format  # Any ill-formatted sources, ...
    - test "$azul_is_sandbox" = 1 && make requirements_update  # ... stale transitive dependencies ...
    - make -C lambdas openapi # ... or changes to the canned OpenAPI definition document ...
    - make check_clean  # would dirty up the working copy and fail the build.
    - make pep8
    - AZUL_DEBUG=0 make test

deploy:
  extends: .base_on_push
  stage: deploy
  script:
    - make auto_deploy
    - make create
  artifacts:
    paths:
      - terraform/plan.json

deploy_browser:
  extends: .base_on_push
  stage: deploy
  needs:
    - build_image
    - deploy
  script:
    - test -e deployments/$deployment.browser || exit 0
    - _link $deployment.browser
    - _refresh
    - cd terraform/browser
    - make auto_apply
  artifacts:
    paths:
      - terraform/browser/plan.json

integration_test:
  extends: .base_on_push
  stage: integration_test
  script:
    - make integration_test

on_success:
  extends: .base_on_push
  stage: teardown
  when: on_success
  script:
    - python scripts/github_status_check.py "${status_context}" success

on_failure:
  extends: .base_on_push
  stage: teardown
  when: on_failure
  script:
    - python scripts/github_status_check.py "${status_context}" failure

early_reindex:
  extends: .base_on_push
  stage: early_reindex
  when: manual
  timeout: 24h
  script:
    - make reindex

reindex:
  extends: .base_on_push
  stage: reindex
  when: manual
  timeout: 24h
  script:
    - make reindex

sell_unused_slots:
  extends: .base
  stage: schedule
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
        && $azul_gitlab_schedule == 'sell_unused_slots'
  script:
    - python3 scripts/sell_unused_slots.py

fedramp_inventory:
  extends: .base
  stage: schedule
  rules:
    - if: $CI_PIPELINE_SOURCE == 'schedule'
        && $azul_gitlab_schedule == 'fedramp_inventory'
  script:
    - python3 scripts/compliance/fedramp_inventory.py fedramp_inventory.xlsx
  artifacts:
    paths:
      - fedramp_inventory.xlsx
    expire_in:
      1 year
