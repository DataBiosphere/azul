azul_vars=(
    # The path to the project root directory
    AZUL_HOME

    # The name of the current deployment. This variable controls the name of all
    # cloud resources and is the main vehicle for isolating cloud resources
    # between deployments.
    AZUL_DEPLOYMENT_STAGE

    # The URL to the DSS (aka Blue box) REST API
    AZUL_DSS_ENDPOINT

    # The name of the hosted zone in Route 53 in which to create user friendly
    # domain names for various API gateways. This hosted zone will have to be
    # created manually prior to running `make terraform`. The value is typically
    # not deployment specific. A subdomain will automatically be created for
    # each deployment.
    AZUL_DOMAIN_NAME

    # A template for the name of the Route 53 record set in the hosted zone
    # specified by AZUL_DOMAIN_NAME. The string {lambda_name} in the template
    # will be substituted with the name of the Lambda function, e.g. `indexer`
    # or `service`. May contain periods.
    AZUL_SUBDOMAIN_TEMPLATE

    # A prefix to be prepended to the names of AWS Lambda functions and
    # associated resources. Must not contain periods.
    AZUL_RESOURCE_PREFIX

    # The host and port of the Elasticsearch instance to use. This takes
    # precedence over AZUL_ES_DOMAIN.
    AZUL_ES_ENDPOINT

    # The name of the AWS-hosted Elasticsearch instance (not a domain name) to
    # use. The given ES domain's endpoint will be looked up dynamically.
    AZUL_ES_DOMAIN

    # Boolean value, 1 to share `dev` ES domain, 0 to create your own
    AZUL_SHARE_ES_DOMAIN

    # Prefix to describe ES indices
    AZUL_INDEX_PREFIX

    # The number of nodes in the AWS-hosted Elasticsearch cluster
    AZUL_ES_INSTANCE_COUNT

    # The EC2 instance type to use for a cluster node
    AZUL_ES_INSTANCE_TYPE

    # The size of the EBS volume backing each cluster node
    AZUL_ES_VOLUME_SIZE

    # Elasticsearch operation timeout in seconds
    AZUL_ES_TIMEOUT

    # The name of the bucket where TerraForm maintains its state, allowing
    # multiple developers to collaboratively use TerraForm in a single AWS
    # account. This bucket is likely going be shared with other projects such as
    # DSS and might require some coordination with the developers of those
    # projects. The special string {account_id} is replaced with the ID of the
    # AWS account the currently configured AWS credentials belong to.
    AZUL_TERRAFORM_BACKEND_BUCKET_TEMPLATE

    # The number of workers pulling files from DSS. There is one such set of DSS
    # workers per index worker!
    AZUL_DSS_WORKERS

    # Whether to create a subscription to DSS during deployment. Set this
    # variable to 1 to enable `make deploy` to subscribe the indexer in the
    # active deployment to DSS bundle events. Making a subscription requires
    # authenticating against DSS using a Google service account specific to this
    # deployment.
    #
    # If making the subscription is enabled, `make terraform` will automatically
    # set up the Google service account for the indexer and deposit its
    # credentials into AWS secrets manager. For this to work you need to
    # configure your *personal* service account credentials in
    # `environment.local` enabling Terraform to create the shared *indexer*
    # service account. The two variables that need to be set are
    # GOOGLE_APPLICATION_CREDENTIALS and GOOGLE_PROJECT. These are well
    # documented. You need to use service account credentials, `gcloud auth
    # login` apparently does not work for this.
    #
    # Set this variable to 0 to prevent the registration of a subscription and
    # to disable the creation of the Google service account. You won't need to
    # configure any Google credentials in that case. Note that disabling the
    # subscription registration won't remove any existing subscriptions. Use
    # `scripts/subscribe.py -U` for that.
    #
    # If you set this variable back from 1 to 0 on an existing deployment, be
    # sure to run `make terraform` right afterwards so the Google cloud
    # resources are physically deleted. After that you may also unset the
    # GOOGLE_.. variables in your environment.
    AZUL_SUBSCRIBE_TO_DSS

    # The number of concurrently running indexer lambda executions. Chalice
    # creates one Lambda function for handling HTTP requests from API Gateway
    # and one additional Lambda function per event handler. The concurrency
    # limit applies to each such function independently. See
    # https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html
    # for details. This setting may also be used to drive other scaling choices,
    # like the number of shards in Elasticsearch.
    #
    AZUL_INDEXER_CONCURRENCY

    # The name of the S3 bucket where the manifest API stores the downloadable
    # content requested by client.
    AZUL_S3_BUCKET

    # Name of the Route 53 zone used for shortened URLs.
    # This hosted zone will have to be created manually prior to running
    # `make terraform`. Personal deployments typically share a zone with the
    # `dev` deployment.
    # If this variable is empty, a route 53 record will not be created and it
    # is assumed that the record and zone have been created manually.  This is
    # the case for staging, integration, and prod environments.
    AZUL_URL_REDIRECT_BASE_DOMAIN_NAME

    # Full domain name to be used in the URL redirection URLs
    # This is also used as the name of the S3 bucket used to store URL
    # redirection objects
    AZUL_URL_REDIRECT_FULL_DOMAIN_NAME

    # Determine if CloudWatch alarms should be deployed (1 yes, 0 no)
    # CloudWatch alarms should not be enabled for personal deployments
    AZUL_ENABLE_CLOUDWATCH_ALARMS

    # Boolean value, 1 to upload a manifest in a single request to S3, 0 to
    # upload the manifest in multiple concurrent requests for equal parts of
    # a smaller size. This allows the manifest generation code to start
    # uploading the manifest to S3 while the manifest data is still being
    # fetched from Elasticsearch, shortening the overall time needed to
    # generate and upload the manifest.
    AZUL_DISABLE_MULTIPART_MANIFESTS
)

unset ${azul_vars[*]}

AZUL_HOME="$(cd -P "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

if [[ ! -f "${AZUL_HOME}/deployments/.active/environment" ]]; then
    echo "Please create a symlink to the active deployment. " \
         "For example 'cd deployments && ln -snf dev .active'"
    return
fi

_set () {
    for var in ${azul_vars[*]}; do
        if [[ ${var} == $1 ]]; then
            eval ": \${$1:='$2'}"
            # Only echo in interactive shells
            if [[ -n $PS1 ]]; then
                self=${BASH_SOURCE[1]#${AZUL_HOME}/}
                if [[ ${!1} == $2 ]]; then
                    echo ${self}: Set $1 to "'$2'"
                else
                    echo ${self}: Not setting $1 to "'$2'"
                fi
            fi
            return
        fi
    done
    echo "Error: variable $1 is missing from azul_vars."
    unset ${azul_vars[*]}
    # That's the only way (I know of) we can exit the sourced script from within
    # a function
    kill -SIGINT $$
}

# Set variables specific to the active deployment and the current user. This is
# the most specific level.
if [[ -f "${AZUL_HOME}/deployments/.active/environment.local" ]]; then
    source "${AZUL_HOME}/deployments/.active/environment.local"
fi

# Set variables specific to the active deployment
source "${AZUL_HOME}/deployments/.active/environment"

# Set variables specific to the current user
if [[ -f "${AZUL_HOME}/environment.local" ]]; then
    source "${AZUL_HOME}/environment.local"
fi

# Set the global defaults. This is the least specific level.

_set AZUL_DOMAIN_NAME "$AZUL_DEPLOYMENT_STAGE.explore.data.humancellatlas.org"  # FIXME: project-specific, is this the right place for this?
_set AZUL_SUBDOMAIN_TEMPLATE "{lambda_name}"
_set AZUL_RESOURCE_PREFIX "azul"
_set AZUL_INDEX_PREFIX "azul"
_set AZUL_ES_DOMAIN "azul-index-$AZUL_DEPLOYMENT_STAGE"
_set AZUL_SHARE_ES_DOMAIN 0
_set AZUL_S3_BUCKET "azul-storage-$AZUL_DEPLOYMENT_STAGE"
_set AZUL_URL_REDIRECT_BASE_DOMAIN_NAME ""
_set AZUL_URL_REDIRECT_FULL_DOMAIN_NAME "$AZUL_DEPLOYMENT_STAGE.url.data.humancellatlas.org"
_set AZUL_ES_INSTANCE_COUNT 2
_set AZUL_ES_INSTANCE_TYPE "r4.2xlarge.elasticsearch"  # Indexing performance benefits from the increased memory offered
                                                       # by the `r` family, especially now that the number of shards is
                                                       # tied to the indexer Lambda concurrency. 2xlarge was chosen
                                                       # heuristically to accomodate scale tests.
_set AZUL_ES_VOLUME_SIZE 70
_set AZUL_ES_TIMEOUT 60  # matches AWS' own timeout on the ELB sitting in front of ES:
                         # https://forums.aws.amazon.com/thread.jspa?threadID=233378
_set AZUL_DSS_WORKERS 8
_set AZUL_INDEXER_CONCURRENCY 64
_set AZUL_SUBSCRIBE_TO_DSS 1
_set AZUL_DISABLE_MULTIPART_MANIFESTS 0

# This is the same TF bucket as the one DSS uses
_set AZUL_TERRAFORM_BACKEND_BUCKET_TEMPLATE "org-humancellatlas-dss-config-{account_id}"
_set AZUL_ENABLE_CLOUDWATCH_ALARMS 0

unset -f _set

export ${azul_vars[*]}

# A little helper to make re-sourcing this script easier.
#
_refresh () {
    source ${AZUL_HOME}/environment
}

# Manage the symlink to the active deployment
#
_select () {
    if [[ $1 != "" ]]; then
        ( # use sub-shell so `cd` is temporary
            cd ${AZUL_HOME}/deployments &&
            test -d "$1" &&
            { [ ! -e .active ] || { [ -L .active ] && rm .active ;} ;} &&
            ln -s "$1" .active
        ) || { echo error: "$1" && return ;}
        _refresh
    fi
    ( cd ${AZUL_HOME}/deployments && ls -l .active )
}

export PYTHONPATH="$AZUL_HOME/src:$AZUL_HOME/test"
export TF_DATA_DIR="${AZUL_HOME}/deployments/.active/.terraform"
