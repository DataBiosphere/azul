from argparse import ArgumentParser
import json
import logging
from pathlib import Path
import shutil
import sys

from azul import config
from azul.files import write_file_atomically
from azul.logging import configure_script_logging

log = logging.getLogger(__name__)


def transform_tf(input_json):
    # Using the default provider makes switching deployments easier
    del input_json['provider']

    assert 'variable' not in input_json
    input_json['variable'] = {'role_arn': {}}

    input_json['output']['rest_api_id'] = {
        'value': '${aws_api_gateway_rest_api.rest_api.id}'
    }

    for func in input_json['resource']['aws_lambda_function'].values():
        assert func['source_code_hash'] == '${filebase64sha256("./deployment.zip")}'
        func['source_code_hash'] = '${filebase64sha256("${path.module}/deployment.zip")}'
        assert func['filename'] == "./deployment.zip"
        func['filename'] = "${path.module}/deployment.zip"

    # TODO: Remove when https://github.com/aws/chalice/issues/1237 is merged.
    # This is tracked in https://github.com/DataBiosphere/azul/issues/1659
    assert 'lifecycle' not in input_json['resource']['aws_api_gateway_deployment']['rest_api']
    input_json['resource']['aws_api_gateway_deployment']['rest_api']['lifecycle'] = {'create_before_destroy': True}

    def patch_cloudwatch_resource(resource_type_name, property_name):
        # Currently, Chalice fails to prefix the names of some resources. We
        # need them to be prefixed with `azul-` to allow for limiting the
        # scope of certain IAM permissions for Gitlab and, more importantly,
        # the deployment stage so these resources are segregated by deployment.
        for resource in input_json['resource'][resource_type_name].values():
            function_name, _, suffix = resource[property_name].partition('-')
            assert suffix == 'event', suffix
            assert function_name, function_name
            resource[property_name] = config.qualified_resource_name(function_name)

    patch_cloudwatch_resource('aws_cloudwatch_event_rule', 'name')
    patch_cloudwatch_resource('aws_cloudwatch_event_target', 'target_id')

    return input_json


def main(argv):
    parser = ArgumentParser(
        description='Prepare the Terraform config generated by `chalice package'
                    '--pkg-format terraform` and copy it into the terraform/ '
                    'directory.'
    )
    parser.add_argument('lambda_name', help='the lambda of the config that will be '
                                            'transformed and copied')
    options = parser.parse_args(argv)
    source_dir = Path(config.project_root) / 'lambdas' / options.lambda_name / '.chalice' / 'terraform'
    output_dir = Path(config.project_root) / 'terraform' / options.lambda_name
    output_dir.mkdir(exist_ok=True)

    deployment_src = source_dir / 'deployment.zip'
    deployment_dst = output_dir / 'deployment.zip'
    log.info('Copying %s to %s', deployment_src, deployment_dst)
    shutil.copyfile(deployment_src, deployment_dst)

    tf_src = source_dir / 'chalice.tf.json'
    tf_dst = output_dir / 'chalice.tf.json'
    log.info('Transforming %s to %s', tf_src, tf_dst)
    with open(tf_src, 'r') as f:
        output_json = json.load(f)
    output_json = transform_tf(output_json)
    with write_file_atomically(tf_dst) as f:
        json.dump(output_json, f, indent=4)


if __name__ == '__main__':
    configure_script_logging(log)
    main(sys.argv[1:])
