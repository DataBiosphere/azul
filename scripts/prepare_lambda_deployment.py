from argparse import (
    ArgumentParser,
)
import json
import logging
import shutil
import sys

from azul import (
    config,
)
from azul.files import (
    write_file_atomically,
)
from azul.logging import (
    configure_script_logging,
)
from azul.terraform import (
    chalice,
    populate_tags,
)

log = logging.getLogger(__name__)


def transform_tf(input_json):
    # Using the default provider makes switching deployments easier
    del input_json['terraform']['required_providers']

    assert 'variable' not in input_json
    input_json['variable'] = {
        'role_arn': {},
        'layer_arn': {},
        'es_endpoint': {},
        'es_instance_count': {},
        'cloudwatch_log_group_provisioner': {}
    }

    input_json['output']['stage_name'] = {
        'value': '${aws_api_gateway_deployment.rest_api.stage_name}'
    }

    for func in input_json['resource']['aws_lambda_function'].values():
        assert 'layers' not in func
        func['layers'] = ["${var.layer_arn}"]

        # Inject ES-specific environment from variables set by Terraform.
        for var, val in config.es_endpoint_env(
            es_endpoint='${var.es_endpoint[0]}:${var.es_endpoint[1]}',
            es_instance_count='${var.es_instance_count}'
        ).items():
            func['environment']['variables'][var] = val

    def patch_cloudwatch_resource(resource_type_name, property_name):
        # Currently, Chalice fails to prefix the names of some resources. We
        # need them to be prefixed with `azul-` to allow for limiting the
        # scope of certain IAM permissions for Gitlab and, more importantly,
        # the deployment stage so these resources are segregated by deployment.
        for resource in input_json['resource'][resource_type_name].values():
            function_name, _, suffix = resource[property_name].partition('-')
            assert suffix == 'event', suffix
            assert function_name, function_name
            resource[property_name] = config.qualified_resource_name(function_name)

    patch_cloudwatch_resource('aws_cloudwatch_event_rule', 'name')
    patch_cloudwatch_resource('aws_cloudwatch_event_target', 'target_id')

    input_json['resource']['aws_api_gateway_deployment']['rest_api']['depends_on'] = [
        'var.cloudwatch_log_group_provisioner'
    ]

    return input_json


def main(argv):
    parser = ArgumentParser(
        description='Prepare the Terraform config generated by '
                    '`chalice package --pkg-format terraform` '
                    'and copy it into the terraform/ directory.'
    )
    parser.add_argument('lambda_name',
                        help='The name of the Lambda function to prepare.')
    options = parser.parse_args(argv)
    lambda_name = options.lambda_name
    src_dir = chalice.package_dir(lambda_name)
    dst_dir = chalice.module_dir(lambda_name)
    dst_dir.mkdir(exist_ok=True)

    args = [dir / chalice.package_zip_name for dir in (src_dir, dst_dir)]
    log.info('Copying %s to %s', *args)
    shutil.copyfile(*args)

    src_tf, dst_tf = [dir / chalice.tf_config_name for dir in (src_dir, dst_dir)]
    log.info('Transforming %s to %s', src_tf, dst_tf)
    with open(src_tf) as f:
        tf_config = json.load(f)
    tf_config = populate_tags(chalice.patch_resource_names(transform_tf(tf_config)))
    with write_file_atomically(dst_tf) as f:
        json.dump(tf_config, f, indent=4)


if __name__ == '__main__':
    configure_script_logging(log)
    main(sys.argv[1:])
