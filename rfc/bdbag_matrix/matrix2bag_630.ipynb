{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HCA: export matrix to Terra as BDBag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this notebook creates a compressed BDBag in the S3 location specified by the environment variable `AZUL_S3_BUCKET`. That bag contains the TSV file with the path to the matrix. A signed URL can be generated so developers at the Broad can start to work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, boto3, botocore, sys, tempfile, urllib.request, urllib.error\n",
    "from bdbag import bdbag_api\n",
    "from shutil import copy, copyfileobj, rmtree\n",
    "from uuid import uuid4\n",
    "from zipfile import ZipFile\n",
    "from filecmp import dircmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the README in case of import errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bag and add a TSV file to it that contains a link to the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TSV file contains only two columns and one row: \n",
    "* the first column, which I entitled _source_ contains the [URL to the portal](https://staging.data.humancellatlas.org/explore/projects)\n",
    "* the second column which I entitled _content_ contains the [URL to the matrix](https://staging.data.humancellatlas.org/explore/projects?filter=%5B%7B%22facetName%22%3A%22project%22%2C%22terms%22%3A%5B%22staging%2FSmart-seq2%2F2019-01-20T23%3A01%3A06Z%22%5D%7D%5D), and which has the HTTP parameter _filter_ to specify the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir_list = os.listdir()\n",
    "bag_path = tempfile.mkdtemp('_bdbag')\n",
    "bag = bdbag_api.make_bag(bag_path)\n",
    "assert os.listdir(os.path.join(bag_path, 'data')) == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy TSV files from current directory into the data directory of the bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(bag_path, 'data')\n",
    "copy('matrix.tsv', data_path)\n",
    "assert 'matrix.tsv' in os.listdir(data_path)\n",
    "bag = bdbag_api.make_bag(bag_path, update=True)  # write checksums into respective files\n",
    "assert bdbag_api.is_bag(bag_path)\n",
    "bdbag_api.validate_bag(bag_path)\n",
    "assert bdbag_api.check_payload_consistency(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_path = bdbag_api.archive_bag(bag_path, 'zip')\n",
    "assert arc_path == bag_path + '.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload zipped bag to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "bucket_name = os.getenv('AZUL_S3_BUCKET')\n",
    "key = 'examples/' + str(uuid4()) + '.zip'\n",
    "if aws_profile is None or bucket_name is None:\n",
    "    sys.exit(\"Check env vars - aborting.\")\n",
    "session = boto3.Session(profile_name=aws_profile)\n",
    "s3 = session.resource('s3')\n",
    "try:\n",
    "    s3.meta.client.upload_file(Filename=arc_path,\n",
    "                               Bucket=bucket_name,\n",
    "                               Key=key)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "rmtree(bag_path, ignore_errors=True)\n",
    "os.remove(arc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm that bag is in bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s3.Object(bucket_name, key).load()\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        print(f'Object {key} not found in S3 bucket {bucket_name}.')\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download compressed bag from bucket (identified by `key`) from S3\n",
    "The original bag named `bag_path` is in `/tmp` and we previously uploaded it to S3. Here we download that bag and write it to the _current working directory_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = s3.Bucket(bucket_name)\n",
    "for item in my_bucket.objects.all():\n",
    "    if item.key == key:\n",
    "        bucket_name = item.bucket_name\n",
    "try:\n",
    "    s3.meta.client.download_file(bucket_name, key, './bag.zip')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "assert 'bag.zip' in os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip bag and list its content\n",
    "The bag's name is (still) `bag_path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('bag.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "assert os.path.basename(bag_path) in os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate signed URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region = os.getenv('AWS_DEFAULT_REGION')\n",
    "session = boto3.session.Session(region_name=aws_region)\n",
    "s3Client = session.client('s3')\n",
    "params = {'Bucket': bucket_name, 'Key': key}\n",
    "expiration_in_secs = 604800  # = 7 days; using Signature Version 4 that's the maximum time\n",
    "url = s3Client.generate_presigned_url('get_object', \n",
    "                                      Params = params, \n",
    "                                      ExpiresIn = expiration_in_secs)\n",
    "print(f'Presigned URL to bag with matrix data: {url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download file using signed URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.basename(bag_path) in os.listdir()\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_path_original = os.path.basename(bag_path) \n",
    "bag_path = os.path.basename(bag_path)\n",
    "try:\n",
    "    os.rename(bag_path_original, bag_path_original + '_original')\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "try:\n",
    "    with urllib.request.urlopen(url) as response, open('bag_from_url.zip', 'wb') as out_file:\n",
    "        copyfileobj(response, out_file)\n",
    "except urllib.error.HTTPError as err:\n",
    "    print(err)\n",
    "    if err.code >= 400:\n",
    "        print('Did the signed URL time out?')\n",
    "assert 'bag_from_url.zip' in os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('bag_from_url.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the original bag with the one downloaded using the signed URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_diff_files(dcmp):\n",
    "    for name in dcmp.diff_files:\n",
    "        print(\"diff_file %s found in %s and %s\" % (name, dcmp.left,\n",
    "               dcmp.right))\n",
    "    for sub_dcmp in dcmp.subdirs.values():\n",
    "        print_diff_files(sub_dcmp)\n",
    "dcmp = dircmp(bag_path, bag_path_original) \n",
    "assert print_diff_files(dcmp) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up local system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdbag_api.cleanup_bag(bag_path)\n",
    "_dirs = [x for x in os.listdir() if x.startswith('tmp')] + [x for x in os.listdir() if x.endswith('.zip')]\n",
    "for _dir in _dirs:\n",
    "    if os.path.isdir(_dir):\n",
    "        rmtree(_dir)\n",
    "    else:\n",
    "        os.remove(_dir)\n",
    "current_dir_list = os.listdir()\n",
    "assert original_dir_list == current_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HCA matrix to Terra",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
