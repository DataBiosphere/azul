{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HCA BDBag export proof-of-principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a BDBag with two files residing in `azul/rfc/bdbag` (see below). Then compress the bag and upload it to S3. Get a signed URL from the bag on S3 and download the bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, boto3, sys, tempfile, uuid, urllib.request\n",
    "from bdbag import bdbag_api\n",
    "from io import StringIO\n",
    "from shutil import rmtree, copy, copyfileobj\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "from filecmp import dircmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to upload data to a FireCloud workspace we need two files, named `participant.tsv` and `sample.tsv`. The first file holds a unique list of donor UUIDs, and the second file the same donor UUIDs with their corresponding specimen UUIDs. The values in these two columns of the table are the composite primary key. The third column in `sample.tsv` holds cell-suspension UUIDs, followed by other columns which I copied from the manifest downloaded from the Explorer of the HCA browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listfiles(basepath):\n",
    "    \"\"\"Return list of file names only, skip directory names found in basepath.\"\"\"\n",
    "    filelist = []\n",
    "    for fname in os.listdir(basepath):\n",
    "        path = os.path.join(basepath, fname)\n",
    "        if os.path.isdir(path):\n",
    "            continue  # skip directories\n",
    "        filelist.append(os.path.basename(path))\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instance of a `bdbag_api` _bag_ object\n",
    "(see https://github.com/fair-research/bdbag/blob/master/doc/api.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir_list = os.listdir()\n",
    "bag_path = tempfile.mkdtemp('_bdbag')  # temporary file name ends with `_bdbag`\n",
    "bag = bdbag_api.make_bag(bag_path)\n",
    "assert os.listdir(os.path.join(bag_path, 'data')) == []  # has data dir. but it's empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get content of TSV files as file objects\n",
    "The next two boxes writes the values of file-like objects to TSV files. This seems foolish, and the only reason I did it is because that's how it's done in _azul_ where we need to write the values of file objects to disk so we can package them into a _BDBag_. Executing the code in the next two boxes has no bearing on the flow of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = {}\n",
    "files = list(filter(lambda x: x.endswith('.tsv'), listfiles(os.getcwd())))\n",
    "for file in files:\n",
    "    file_object[os.path.splitext(file)[0] + '_tsv'] = StringIO()\n",
    "    writer = csv.writer(file_object[os.path.splitext(file)[0] + '_tsv'],\n",
    "                        dialect='excel-tab')\n",
    "    with open(file) as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the values of the file objects we just created to disk. The file sizes are off by 4-6 bytes compared to the existing files (their content is the same). I think the reason is the longer file names (4 more characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname, fobj in file_object.items():\n",
    "    f = open(fname + '.tsv', 'w')\n",
    "    f.write(fobj.getvalue())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy TSV files from current directory into the data directory of the bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(bag_path, 'data')\n",
    "files = list(filter(lambda x: x.endswith('.tsv'), listfiles(os.getcwd())))\n",
    "for file in files:\n",
    "    copy(file, data_path)\n",
    "assert ['participant.tsv', 'sample.tsv'] == listfiles(data_path)\n",
    "bag = bdbag_api.make_bag(bag_path, update=True)  # write checksums into respective files\n",
    "assert bdbag_api.is_bag(bag_path)\n",
    "bdbag_api.validate_bag(bag_path)\n",
    "assert bdbag_api.check_payload_consistency(bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_path = bdbag_api.archive_bag(bag_path, 'zip')\n",
    "assert arc_path == bag_path + '.zip'  # arc_path has same basename and .zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload zipped bag to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_profile = os.getenv('AWS_PROFILE')\n",
    "bucket_name = os.getenv('AZUL_S3_BUCKET')\n",
    "key = str(uuid.uuid4()) + '.zip'\n",
    "if aws_profile is None or bucket_name is None:\n",
    "    sys.exit(\"Check env vars - aborting.\")\n",
    "session = boto3.Session(profile_name=aws_profile)\n",
    "s3 = session.resource('s3')\n",
    "try:\n",
    "    s3.meta.client.upload_file(Filename=arc_path,\n",
    "                               Bucket=bucket_name,\n",
    "                               Key=key)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "rmtree(bag_path, ignore_errors=True)\n",
    "os.remove(arc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download compressed bag from bucket (identified by `key`) from S3\n",
    "The original bag named `bag_path` is in `/tmp` and we previously uploaded it to S3. Here we download that bag and write it to the _current working directory_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = s3.Bucket(bucket_name)\n",
    "for item in my_bucket.objects.all():\n",
    "    if item.key == key:\n",
    "        bucket_name = item.bucket_name  # should be same as above\n",
    "try:\n",
    "    s3.meta.client.download_file(bucket_name, key, './bag.zip')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "assert 'bag.zip' in os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip bag and list its content\n",
    "The bag's name is (still) `bag_path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('bag.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "assert os.path.basename(bag_path) in os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate signed URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region = os.getenv('AWS_DEFAULT_REGION')\n",
    "session = boto3.session.Session(region_name=aws_region)\n",
    "s3Client = session.client('s3')\n",
    "params = {'Bucket': bucket_name, 'Key': key}\n",
    "expiration_in_secs = 60\n",
    "url = s3Client.generate_presigned_url('get_object', \n",
    "                                      Params = params, \n",
    "                                      ExpiresIn = expiration_in_secs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download file using signed URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.path.basename(bag_path) in os.listdir()\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_path_original = os.path.basename(bag_path) \n",
    "bag_path = os.path.basename(bag_path)\n",
    "os.rename(bag_path_original, bag_path_original + '_original')\n",
    "try:\n",
    "    with urllib.request.urlopen(url) as response, open('bag_from_url.zip', 'wb') as out_file:\n",
    "        copyfileobj(response, out_file)\n",
    "except HTTPerror as err:\n",
    "    print(err)\n",
    "assert 'bag_from_url.zip' in os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('bag_from_url.zip','r') as zip_ref:\n",
    "    zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the original bag with the one downloaded using the signed URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_diff_files(dcmp):\n",
    "    for name in dcmp.diff_files:\n",
    "        print(\"diff_file %s found in %s and %s\" % (name, dcmp.left,\n",
    "               dcmp.right))\n",
    "    for sub_dcmp in dcmp.subdirs.values():\n",
    "        print_diff_files(sub_dcmp)\n",
    "dcmp = dircmp(bag_path, bag_path_original) \n",
    "assert print_diff_files(dcmp) is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdbag_api.cleanup_bag(bag_path)\n",
    "_dirs = [x for x in os.listdir() if x.startswith('tmp')] + [x for x in os.listdir() if x.endswith('.zip')]\n",
    "for _dir in _dirs:\n",
    "    if os.path.isdir(_dir):\n",
    "        rmtree(_dir)\n",
    "    else:\n",
    "        os.remove(_dir)\n",
    "current_dir_list = os.listdir()\n",
    "assert original_dir_list == current_dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
